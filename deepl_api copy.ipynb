{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install deepl fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use 3.12.4\n",
    "import os\n",
    "import re\n",
    "import deepl\n",
    "\n",
    "key_path = '/Users/jaesolshin/Documents/GitHub/pdf_translator/key.txt'\n",
    "auth_key = open(key_path, 'r', encoding='utf-8').read()  # Replace with your key\n",
    "translator = deepl.Translator(auth_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "folder_path = \"/Users/jaesolshin/Library/CloudStorage/GoogleDrive-ysys143@gmail.com/내 드라이브/2024-2/Critical AI/main/\"\n",
    "filename = \"2.5 PROXIES, OR RECONSTRUCTING THE UNKNOWN.pdf\"\n",
    "title1 = \"PROXIES, OR RECONSTRUCTING THE UNKNOWN\"\n",
    "title2 = \"PROXIES, OR RECONSTRUCTING THE UNKNOWN\"\n",
    "doc = fitz.open(folder_path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Throughout the preceding pages, we have explored how proxies can serve  to buttress— and justify— discrimination. Correlations produce proxies.  In statistics and economics, most proxies correspond linearly and associate with hidden or unknown variables. Effectively acting as standins or  surrogates, proxies reveal protected categories such as race and gender  in seemingly colorblind or agentbased categories such as zip code or  “age at first arrest.” According to the Oxford English Dictionary, the word  “proxy” stems from the classical Latin procurator, which means “manager,  superintendent, agent, steward, financial administrator of a province,  attorney,” but which became, in postclassical times, “proctor in the ecclesiastical courts . . . [and] university official.” Over time, a proxy ensured  direct and equivalent substitution, empowering a person to represent and  act for another, becoming, in the Christian Church, “an annual payment  by incumbents . . . as a substitute for providing for or entertaining a visiting bishop or his representative(1). Proxies were thus first human substitutes or agents, then payments given in lieu of services. Proxies, though,  seem less independent than agents: they are not supposed to go rogue or  take a cut. As Cathy O’Neil has argued, those building “weapons of math destruction” use proxies to infer behavior they are interested in but cannot  directly access: “They draw statistical correlations between a person’s zip \n",
      "\n",
      " PROXIES, OR RECONSTRUCTING  THE UNKNOWN\n",
      "\n",
      " code or language patterns and her potential to pay back a loan or handle  a job. These correlations are discriminatory, and some of them are illegal(2). Much effort has been spent exposing proxies that violate the spirit,  if not the letter, of antidiscrimination legislation. Without doubt, this is  important, but is it enough? Blaming proxies for race for racist discrimination presumes that racism  naturally stems from visible difference— that if we just didn’t track race,  racism would disappear. As many studies and the first half of this book  have clearly shown, however, it would not, and, indeed, this colorblind  presumption— this hopeful ignorance— is dangerous(3). Three questions  spring to mind here: How do seemingly race, genderand differencefree  models perpetuate discrimination? What do the proxies that help them  perpetuate discrimination reference and do? And how can we use the  results of these models “against the grain,” as evidence of discriminatory  practices? Amazon’s AI hiring program, which routinely favored men over  women applicants despite comparable résumés, was trained using Amazon’s historical hiring data. How could we use that model to document  and understand discriminatory hiring practices within the tech industry? What would happen if we treated these and other models as we do  global climate change models? Climate models predict the most probable  future for the world, given past and current actions, not so that we will  fatalistically accept the future they predict, but rather so that we will do  whatever is needed to prevent that future from occurring(4). Being accurate  in the narrowest sense of this word— encouraging us to keep producing  hydrocarbons so that we verify their predictions— is not the point. When  a global climate change model we have good reason to trust predicts a  rise of two degrees Celsius in the global temperature, we seek to fix the  world, not the model that predicts them— unless, of course, we are global  climate change deniers. This analogy to global climate change models also reveals the limits  of models and explanations. Despite overwhelming scientific consensus on and evidence of climate change and its increasingly destructive  effects, there has been a decided lack of action. As activists and community members following the comprehensive report on policing discrimination in Ferguson, Missouri, noted, the report “put into written form  what so many people have already voiced for years about change that  needs to happen in the St. Louis region, but identifying a problem and  fixing it are different(5). Further, identifying the obvious can also become  an excuse for inaction: Do we really need more models to uncover policing discrimination, which is hardly “undercover”? As for Amazon’s hiring algorithm, for whom is the fact that the tech industry discriminates  against women news? The example of global climate change models also complicates critiques of proxies— it points to their necessity and to the political struggles  they inevitably evoke. I therefore place social networking algorithms next  to global climate change models to make us pause: to shake loose our normal assumptions and conclusions and, in particular, to make us reconsider blanket critiques of proxies. \n",
      "\n",
      "VISUALIZING THE REAL\n",
      "\n",
      " That our early twentyfirstcentury world has undergone climate change  seems indisputable. As NASA pointed out in 2020, nineteen of the warmest years ever recorded have occurred since 2000, and 2016 and 2020 were  tied for the warmest years on record (see figure 33). Given this, that there is any debate about the human impact on global  climate change mystifies many, especially those living outside the United  States. The challenge, it would appear, lies in bridging the gap between  personal experience and global phenomena, in convincing people that  something they cannot easily experience— climate— is changing, before it  33 Global Land– Ocean Temperature Index, from NASA: Global Climate Change: Vital  Signs of the Planet, https://climate.nasa.gov/vital-signs/global-temperature. is too late. As NASA climatologist Jim Hansen and colleagues put it: “The  greatest barrier to public recognition of humanmade climate change is  probably the natural variability of local climate. How can a person discern longterm climate change, given the notorious variability of local  weather and climate from day to day and year to year?”6 In 2015, on a  cold winter day in Washington, D.C., U.S. Senator Jim Inhofe notoriously  offered his fellow senators a snowball as icecold evidence that global  warming was a hoax(7). To visualize what cannot be experienced, climate scientists, journalists, and citizen groups have turned to visual proxies: from photographs  of melting icebergs and starving polar bears to scientific graphs of historical temperature increases. These visual proxies serve as standins or  representatives for rising global temperatures. But, like all proxies, they  are doubleedged: the same image can foster both belief and mistrust.  National Geographic’s “heartwrenching video [of] a starving polar bear on  iceless land” on Summerset Island (figure 34), for example, went viral—  sparking outrage over the effects of global climate change(8). In response, conservative news outlets and questionable wildlife “conservation” sites, such as Polar Bears International, spread competing  34 Still frame from “HeartWrenching Video Shows Starving Polar Bear on Iceless Land,”  National Geographic, December 7, 2017. Footage: Paul Nicklen for SeaLegacy, https:// www.nationalgeographic.com/science/article/polar-bear-starving-arctic-sea-ice-melt  -climate-change-spd. explanations for the bear’s condition and accused SeaLegacy of “tragedy  porn(9). The more compelling and popular the image, the more controversy, analysis, and conspiracy theories it accretes— and disseminates.  Proxies both reduce and introduce uncertainty. By representing the  unknown or absent, they evoke the specter of the unknowable. Perhaps no image has been more controversial in the ongoing climate change debate than Mann, Bradley, and Hughes’s “hockey stick”  (figure 35). Although charismatic megafauna and dramatic natural settings spark interest and debate, the most influential— and controversial—  representation of global climate change has been a line graph.  Climatologists Michael Mann, Raymond Bradley, and Malcolm Hughes  first published their graph charting changes in mean temperature in the  Northern Hemisphere from 1400 to 1995, in Nature in 1998; the following year, they published an updated version, which included the period  from 1000 to 1998, in Geophysical Research Letters(10). Departures in Temperature (°C) from the 1961–1990 Average Year Mann et al., 1999, reconstruction (annual mean, full hemisphere) Mann et al., 1999, reconstruction (annual mean, 30°N to 70°N latitude band) Jones et al., 1998, reconstruction (summer, extra-tropical emphasis) Briffa, 2000, reconstruction (tree-ring density only, summer, extra-tropical) Instrumental data (annual mean, full hemisphere) 1(0). 0(5). 0(0). –0(5). –1(0). 1000 1200 1400 1600 1800 2000 35 “Hockey Stick,” redrawn from figure 4(2). in Michael E. Mann, The Hockey Stick  and the Climate Wars: Dispatches from the Front Lines (New York: Columbia University  Press, 2012), 55. The 2001 Intergovernmental Panel on Climate Change (IPCC) report  featured the researchers’ 1999 graph in the “Summary for Policymakers”  section, and politicians such as President Bill Clinton and Vice President  Al Gore used it to reveal the impact of the human burning of fossil fuels  on climate. At the same time, the image was attacked both by social scientists and by physicists who were global climate change deniers and whose  attacks were picked up by media outlets such as the Wall Street Journal and  MIT Technology Review and by conservative politicians(11). Further, Mann  was personally attacked as a proxy for “bad science”: he and his family  received death threats; his academic records were unsuccessfully subpoenaed by Republican lawmakers, and his emails were hacked as part of  “Climategate(12). How could a simple graph provoke so much anger and controversy? \n",
      "\n",
      "STICKING TO THE PAST\n",
      "\n",
      " Given that Mann, Bradley, and Hughes’s hockey stick makes no predictions about the future— the last year included in the 1999 graph was  1998— the controversy seems bizarre. The researchers’ model would  seem to be explanatory rather than predictive. Mann specializes in  paleoclimatology: the hockey stick did not predict future climate trends  using general circulation models but rather reconstructed past climates  using statistical methods and proxy data, such as measurements of tree  rings and ice cores. But, as Mann, Bradley, and Hughes noted in their  1998 paper: “Knowing both the spatial and temporal patterns of climate change over the past several centuries remains a key to assessing  a possible anthropogenic impact on postindustrial climate(13). In other  words, the recreated past can reveal the impact of our current use of   fossil fuels. The researchers’ 1999 graph was so controversial because it reconstructed the average temperature in the Northern Hemisphere from 1000  to 1400, during the socalled medieval warming period (also called the  “medieval climate anomaly”), when parts of Europe, China, Australia,  and North America experienced unusually high temperatures. Based on  this anomaly, climate change deniers such as Rick Perry, President Donald Trump’s first secretary of energy, have claimed that climate change is  mainly caused by the oceans and the natural environment— rather than  by humans(14). The argument goes like this: If the Earth has undergone a  similar period of warming in the past, then humans cannot be blamed  for the current warming. The hockey stick graph, however, showed that  warming during the twentieth century— the blade of the stick— dwarfed  any prior temperature increase. Given that the main difference between  now and then is the human burning of fossil fuels, humans must be  responsible for the far greater rise in the global mean temperature. The “scientific” attacks on Mann, Bradley, and Hughes focused on  their use of proxies and statistical methods. Mann, like paleoclimatologists before him, drew from many different types of proxies for temperature, such as tree ring measurements, ice cores, ice melts, and local  weather records, that are unevenly sampled both temporally and spatially. In particular, there is an overwhelming abundance of tree ring data,  which represent, as Mann explained in his 2012 book, “only a restricted  region of the globe, the midlatitude continents.” Less abundant temperature proxies— data drawn from corals, ice cores, and lake sediments—  represent vast regions elsewhere: the poles, oceans, and tropics. If all  these temperature proxies were treated equally, “the sheer amount of tree  ring data [would] overwhelm the less abundant information from other  proxy records . . . [and thus] weight our results toward the midlatitude  continents(15). To create a “fair fight” between these different proxies,  Mann, Bradley, and Hughes used principal component analysis (PCA)  and singular value decomposition (SVD), methods previously introduced  into meteorology and oceanography by physical scientist Rudolph Preisendorfer(16). As mentioned in chapter 1 and as will be further elaborated in  chapter 4, principal component analysis was originally developed in the  early twentieth century by Karl Pearson, a “father” of modern statistics,  biometrician, and eugenicist(17). PCA resolves a set of possibly correlated data points— observations  that may include overlapping factors— into a set of linearly uncorrelated  orthogonal “principal components” by determining the “eigenvectors”  of the correlation matrix (see figures 36 and 37). In effect, principal component analysis breaks data down into a set  of vectors to reveal significant patterns: the first principal component  will explain the greatest variation since most of the data lie along that component’s axis; the second principal component, the next greatest  variation; and so on. More simply, principal component and eigenvector  analysis recenter data around a new set of axes, which makes mathematical calculations much easier. Mann, Bradley, and Hughes used principal component analysis in two  ways: (1) to “even out” the data spatially; and, more controversially, (2)  to determine the leading patterns of variation in their larger data set.  Each eigenvector they produced was resolved into both a spatial component— an “empirical orthogonal function”— as well as a principal component over time (figure 38). 1400 1500 1600 1700 1800 1900 0(00). –0(10). –0(05). 0(05). 0(00). –0(10). –0(05). 0(05). 0(00). –0(10). –0(05). 0(05). 0(00). –0(10). –0(05). 0(05). 0(00). –0(10). –0(05). 0(05). 0(10). Year RPC no. 1 RPC no. 2 RPC no. 3 RPC no. 4 RPC no. 5 36 Dominant principal components, redrawn from Michael E. Mann, Raymond S. Bradley, and Malcolm K. Hughes, “GlobalScale Temperature Patterns and Climate Forcing over the Past Six Centuries,” Nature 392, no. 6678 (1998): 783, figure 5a, https:// meteor.geol.iastate.edu/classes/ge515/papers/Mann_et_al_Nature1998.pdf. 37 “Principal Component Analysis (PCA),” by Alex Barnett. 37 (continued) 37 (continued) 37 (continued) 38 Empirical orthogonal functions for the five leading eigenvectors, redrawn from  Mann, Bradley, and Hughes, “GlobalScale Temperature Patterns,” 780, figure 2, https://  meteor.geol.iastate.edu/classes/ge515/papers/Mann_et_al_Nature1998.pdf. According to Mann, Bradley, and Hughes, the first eigenvector, which  described 88 percent of the variability in global mean temperature and  73 percent of the variation in the hemispheric mean temperature, clearly  showed a rise in mean temperature during the twentieth century. In contrast, the second showed a modest La Niñalike cooling trend in the eastern tropical Pacific. The researchers used twentiethcentury data to determine these patterns of variation because all proxies were available then. They then  calibrated “each of the indicators in the multiproxy data against these  empirical eigenvectors at annualmean resolution during the 1902– 80  training period” using singular value decomposition (SVD), which helped  produce reconstructed principal components over a longer historical  time period(18). Each principal component was the weighted sum of some  or all of the measured variables or proxies: the first principal component  might, for instance, weight one proxy by .5, and another by .25. To verify  the reconstructed principal components, they tested the components’  predictions against actual data for the periods before the twentieth century (hence the error bars above and below the hockey sticks). They also  changed the number of proxies and eigenvectors used during different  time periods, since not all proxies were available or pertinent for each  eigenvector and time period. The reconstructions from 1820 onward, for  instance, used the full multiproxy network of 112 indicators and resolved  eleven eigenvectors, whereas the period from 1820 to 1760 used 93 indicators and resolved nine eigenvectors. The number of available proxies  and resolved eigenvectors diminished with each time period. Within the  five most significant reconstructed principal components they uncovered, the first showed an increase in temperature over time, and the second revealed a slight decrease in temperature, in line with its associated  empirical orthogonal function. Through this analysis, they determined  that the most important pattern was one of temperature increase in the  Northern Hemisphere. Critics attacked Mann, Bradley, and Hughes for their use of proxies and  for their training set. In 2003, two astrophysicists based at the Harvard Smithsonian Center for Astrophysics, Willie Soon and Sallie Baliunas,  argued in the journal Climate Research that multiproxy networks were  inherently inaccurate: “The results from the proxy indicators cannot  be combined into a hemispheric or global quantitative composite” but  should rather be “considered as an ensemble of individual expert opinions”;19 in other words, each individual proxy— each tree ring and ice  core, for instance— should be given an equal voice. But the overwhelming amount of the tree ring data from midlatitude areas in Mann, Bradley,  and Hughes’s papers meant that, in effect, they were only listening to  these data, which, not surprisingly, sang of global warming during the  medieval period. The Soon and Baliunas paper, however, whose main  conclusion was championed by denier politicians like Inhofe, was shown  to be riddled with errors, and the peer review process that led to its publication deeply flawed. Indeed, climate scientist Hans von Stroch, chief  editor of Climate Research and a critic of Mann, Bradley, and Hughes’s  research, as well as several other editors, resigned in protest(20). In 2005,  Canadian businessman Stephen McIntyre and social scientist Ross McKitrick reviewed Mann, Bradley, and Hughes’s 1998 study and asserted  that the researchers’ use of the shorter calibration period guaranteed that  any data fed into their model would produce a hockey stick pattern(21).  McIntyre and McKitrick’s paper was also deeply flawed, its results were so  different from those of Mann, Bradley, and Hughes because it removed  the principal component responsible for warming when they recentered  their data around the longer calibration period(22). A 2006 report from the National Academy of Science validating Mann,  Bradley, and Hughes’s hockey stick and a 2011 report by physicist Richard  Muller at UC Berkeley, a former climate change denier, effectively silenced  criticisms of the hockey stick studies. Muller, who had previously referred  to McIntyre and McKitrick’s paper as a “bombshell” that revealed the  bad science behind global climate change research, was himself funded  by the Koch brothers to “revisit” the hockey stick(23). In his 2011 report to  the Wall Street Journal, however, Muller revealed that, after using “real”  data to reconstruct mean temperatures in the Northern Hemisphere, he  had found the warming effect to be even more pronounced than Mann,  Bradley, and Hughes had suggested. Conceding the point without issuing a direct apology, Muller wrote in the Wall Street Journal: “When we  began our study, we felt that skeptics had raised legitimate issues, and we  didn’t know what we’d find. Our results turned out to be close to those  published by prior groups. We think that means that those groups had truly been very careful in their work, despite their inability to convince  some skeptics of that. They managed to avoid bias in their data selection,  homogenization and other corrections(24). Muller won a prize from Foreign Policy for his aboutface— in stark contrast to the death threats and harassment Mann received. Attacked as a  proxy for “bad science,” Mann, like LawrenceLivermore National Laboratory atmospheric scientist Benjamin D. Santer before him, became an  example for others in the field of climate change science. Mann called  the campaign to isolate and harass certain climate change scientists the  “Serengeti strategy,” after the way predators in the Serengeti pick off the  most vulnerable prey animals from the rest of “the herd(25). \n",
      "\n",
      "EMBRACING PROXY POLITICS\n",
      "\n",
      " Mann, Bradley, and Hughes’s hockey stick and Kosinski and colleagues’  analytic models (described in chapter 1) are similar. In building them,  both groups of researchers used matrix decomposition methods; both  sought to reconstruct a past and a future; and both struggled with questions of authentication. Linearity underlies these models: the past and future correspond to  each other. As Mann, Bradley, and Hughes note in their 1998 paper, their  model makes three fundamental assumptions: (1) “the indicators in our  multiproxy trainee network are linearly related to one or more of the  instrumental training patterns”; (2) linearity across space and time (sampling in one part of a region represents the larger area); and (3) the spatial  patterns of variation of climate within one part of the past century are  similar to those during the entire past century(26). These profound assumptions of linearity buttress the researchers’ explanations— they also form  the basis for proxies more generally. Proxies are not inherently “innocent” but neither are they inherently  “guilty.” They are central to both understanding global climate change  and to creating “weapons of math destruction.” When used to seek the  unknown or absent, they introduce uncertainty, even as they serve to  reduce it. Proxies are necessary and inadequate: indeed, they point to  inadequacies in direct knowledge more generally. As historian of science  and curator Christoph Rosol has argued, paleoclimatology must use and  negotiate proxies, even though doing so troubles the boundary between  data and model(27). Proxies are fundamentally “ambivalent,” and our current politics engages proxies at all levels(28). A proxy embodies what Jacques  Derrida called a “pharmakon,” a supplement or intermediary: “a philter,  which acts as both remedy and poison(29). Proxies absolve one of responsibility— a payment in lieu of hospitality— by creating new dependencies  and relations. Proxies touch the unknown: they extend the knowable, by  capturing or “syncing up with” what is not there. Proxies spark controversy and raise questions about the relations they “uncover.” Indeed, the parallels between global climate change models and social  networking analyses raise the provocative question: How and when do  humans become as predictable as trees? They point both to an entire  mechanism of “training” needed to shape reality so that humans behave  linearly and to a massive data collection network that buttresses this  training and is buttressed by it. Perversely, this linearity comes about not  through “mass” reproduction of the same, but rather through efforts to  automate authenticity. \n"
     ]
    }
   ],
   "source": [
    "full_text = \"\"\n",
    "\n",
    "for page in doc:\n",
    "    page_text = page.get_text()\n",
    "    page_text = page_text.replace('-\\n', '')  # \\n 제거\n",
    "    page_text = page_text.replace('\\n', ' ')  # \\n 제거\n",
    "    full_text += page_text\n",
    "\n",
    "#full_text = full_text.replace('\\n', ' ')\n",
    "full_text = full_text.replace('- ', '')\n",
    "\n",
    "# '\\xa0.'을 '.'로 치환\n",
    "text = re.sub(r\"\\xa0\\.\", \".\", text)\n",
    "\n",
    "# 점, 숫자 뒤에 공백이 있는 패턴(각주)을 괄호로 감싸기\n",
    "full_text = re.sub(r\"\\.['”\\\"“‘]?(\\d+)\\s\", r\"(\\1). \", full_text)\n",
    "\n",
    "# 정규 표현식으로 공백+ 숫자 + 공백 + {title1} 패턴을 찾고 삭제\n",
    "pattern = rf\"\\s*\\d+\\s*{re.escape(title1)}\"\n",
    "full_text = re.sub(pattern, \"\", full_text)\n",
    "\n",
    "# 정규 표현식으로 {title2} + 공백 + 숫자 + 공백 패턴을 찾고 삭제\n",
    "pattern = rf\"{re.escape(title2)}\\s*\\d+\\s*\"\n",
    "full_text = re.sub(pattern, \"\", full_text)\n",
    "\n",
    "# 대문자, 공백, 쉼표로 이루어진 패턴을 찾아 앞뒤로 줄바꿈 추가\n",
    "# except_list에 포함되지 않은 경우에만 개행 추가\n",
    "except_list = [\"OCEAN\", \"OCEAN \", \" OCEAN,\", \"XXVII\", \"IPIP\", \"AFST\", \"LASSO\", \"SVD \", \n",
    "               \"PERSONALITY\", \"PARTICIPANT’S\", \"LIKES LINEAR REGRESSION MODELS\", \" COMPUTERS’\", \"JUDGMENTS A\", \n",
    "               'LAUNDERING “OUR” PAST', \"MOOC\", \"BASR\", \"PJS,\", \"NASA\", \"MIT\", \" MIT\"]\n",
    "full_text = re.sub(r\"(?<!\\S)([A-Z\\s,]{4,})(?!\\S)\",\n",
    "    lambda m: f\"\\n\\n{m.group(1)}\\n\\n\" if m.group(1) not in except_list else m.group(1),\n",
    "    full_text\n",
    ")\n",
    "\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앞 페이지에서 프록시가 어떻게 차별을 정당화하거나 정당화하는 역할을 할 수 있는지 살펴봤습니다. 상관관계는 프록시를 생성합니다.  통계와 경제학에서 대부분의 프록시는 선형적으로 대응하며 숨겨진 변수 또는 알려지지 않은 변수와 연관됩니다. 효과적으로 대리인 또는 대리인 역할을 하는 프록시는 인종, 성별과 같은 보호 대상 범주를 우편번호나 \"최초 체포 연령\"과 같이 겉보기에는 색맹 또는 대리인 기반 범주에서 드러냅니다. 옥스퍼드 영어 사전에 따르면 \"대리인\"이라는 단어는 \"관리자, 감독관, 대리인, 청지기, 지방의 재정 관리자, 변호사\"를 의미하는 고전 라틴어 프로큐레이터에서 유래했지만 고전 이후 시대에는 \"교회 법원의 감독관 ... . [그리고] 대학 관리\"가 되었습니다. 시간이 지나면서 대리인은 직접적이고 동등한 대리권을 보장하여 한 사람이 다른 사람을 대리하고 행동할 수 있는 권한을 부여했으며, 기독교 교회에서는 \"현직 주교나 그 대리인을 부양하거나 접대하는 대신에 ... 현직 주교가 매년 지불하는 돈\"으로 자리 잡게 되었습니다(1). 따라서 대리인은 처음에는 사람을 대신하거나 대리인이었고, 그다음에는 서비스를 대신하여 지급하는 대가였습니다. 하지만 프록시는 대리인보다 독립성이 떨어지기 때문에 부정행위를 하거나 폭리를 취해서는 안 됩니다. 캐시 오닐이 주장했듯이, '수학 파괴 무기'를 만드는 사람들은 프록시를 사용하여 관심은 있지만 직접 접근할 수 없는 행동을 추론합니다: \"그들은 사람의 지퍼와 지퍼 사이의 통계적 상관관계를 도출합니다.\n",
      "\n",
      " 프록시, 또는 미지의 것을 재구성하는 것\n",
      "\n",
      " 코드 또는 언어 패턴과 대출금 상환 또는 업무 처리 가능성 사이의 통계적 상관관계를 도출합니다. 이러한 상관관계는 차별적이며, 그 중 일부는 불법입니다(2). 차별 금지법의 문자는 아니더라도 그 정신을 위반하는 프록시를 폭로하는 데 많은 노력을 기울여 왔습니다. 의심할 여지 없이 중요한 일이지만, 이것으로 충분할까요? 인종 차별을 인종에 대한 프록시를 탓하는 것은 인종 차별이 당연히 눈에 보이는 차이에서 비롯된다는, 즉 인종만 추적하지 않으면 인종 차별이 사라질 것이라는 가정을 전제로 합니다. 그러나 많은 연구와 이 책의 전반부에서 분명히 밝혀진 바와 같이, 인종 차별은 사라지지 않으며, 실제로 이러한 색맹적 추정, 즉 희망에 찬 무지는 위험합니다(3). 여기서 세 가지 질문이 떠오릅니다: 인종, 성별, 차이가 없는 것처럼 보이는 모델이 어떻게 차별을 영속화할까요? 차별을 영속화하는 데 도움을 주는 프록시는 무엇을 참조하고 무엇을 하는가? 그리고 이러한 모델의 결과를 차별적 관행의 증거로 어떻게 '정반대'로 사용할 수 있을까요? 비슷한 이력서에도 불구하고 여성 지원자보다 남성을 더 선호했던 Amazon의 AI 채용 프로그램은 Amazon의 과거 채용 데이터를 사용하여 학습되었습니다. 이 모델을 사용하여 기술 업계 내 차별적인 채용 관행을 문서화하고 이해하려면 어떻게 해야 할까요? 이러한 모델과 다른 모델을 전 세계 기후 변화 모델과 마찬가지로 취급한다면 어떤 일이 일어날까요? 기후 모델은 과거와 현재의 행동을 고려할 때 가장 가능성이 높은 미래를 예측하는데, 그 예측된 미래를 운명론적으로 받아들이기 위해서가 아니라 그 미래를 막기 위해 필요한 모든 조치를 취하기 위해서입니다(4). 가장 좁은 의미의 정확성, 즉 예측을 검증하기 위해 탄화수소를 계속 생산하도록 장려하는 것은 요점이 아닙니다. 우리가 신뢰할 만한 충분한 이유가 있는 지구 기후 변화 모델이 지구 기온이 섭씨 2도 상승할 것이라고 예측한다면, 물론 우리가 지구 기후 변화를 부정하는 사람이 아닌 이상, 우리는 예측한 모델이 아니라 세상을 고치려고 노력해야 합니다. 지구 기후 변화 모델에 대한 이러한 비유는 모델과 설명의 한계를 드러내기도 합니다. 기후 변화와 그 파괴적인 영향에 대한 압도적인 과학적 합의와 증거가 있음에도 불구하고 이에 대한 행동은 결정적으로 부족합니다. 미주리주 퍼거슨의 경찰 차별에 관한 종합 보고서를 접한 활동가들과 지역사회 구성원들은 이 보고서가 \"세인트루이스 지역에서 일어나야 할 변화에 대해 이미 수년 동안 많은 사람들이 목소리를 높여온 내용을 문서화했지만, 문제를 파악하는 것과 문제를 해결하는 것은 다릅니다(5)\"라고 지적했습니다. 또한, 명백한 문제를 파악하는 것은 행동하지 않는 핑계가 될 수도 있습니다: '은밀'하지도 않은 경찰의 차별을 밝혀내기 위해 더 많은 모델이 필요할까요? 아마존의 채용 알고리즘의 경우, 기술 업계가 여성을 차별한다는 사실이 누구를 위한 뉴스일까요? 전 세계 기후 변화 모델의 예는 또한 대리인에 대한 비판을 복잡하게 만듭니다. 대리인의 필요성과 필연적으로 유발되는 정치적 투쟁을 지적합니다. 따라서 저는 소셜 네트워킹 알고리즘을 글로벌 기후 변화 모델 옆에 배치하여 우리의 일반적인 가정과 결론을 흔들고, 특히 프록시에 대한 포괄적인 비판을 재고하도록 합니다.\n",
      "\n",
      "현실을 시각화하다\n",
      "\n",
      " 21세기 초의 세계가 기후 변화를 겪었다는 사실은 의심의 여지가 없어 보입니다. NASA가 2020년에 지적했듯이, 2000년 이후 가장 따뜻한 해 중 19년이 기록되었고, 2016년과 2020년은 기록상 가장 따뜻한 해로 동률을 이뤘습니다(그림 33 참조). 이러한 점을 고려할 때, 지구 기후 변화에 대한 인간의 영향에 대한 논쟁은 많은 사람들, 특히 미국 이외의 지역에 거주하는 사람들에게 의문을 불러일으킵니다. 문제는 개인적 경험과 전 지구적 현상 사이의 간극을 좁히고, 사람들이 쉽게 경험할 수 없는 기후가 변화하고 있다는 사실을 설득하는 데 있는 것으로 보입니다 33 전 세계 육지-해양 온도 지수, NASA: 지구 기후 변화: 지구의 생체 신호, https://climate.nasa.gov/vital-signs/global-temperature. 너무 늦었습니다. NASA의 기후학자 짐 한센과 동료들은 다음과 같이 말합니다: \"인간이 만든 기후 변화에 대한 대중의 인식을 가로막는 가장 큰 장벽은 아마도 지역 기후의 자연적인 변동성일 것입니다. 날마다, 해마다 악명 높은 지역 날씨와 기후의 변동성을 고려할 때 어떻게 장기적인 기후 변화를 식별할 수 있을까요?\"6 2015년 워싱턴 DC의 추운 겨울날, 미국 상원의원 짐 인호프는 지구 온난화가 사기라는 증거로 동료 상원의원들에게 눈덩이를 제공한 것으로 악명이 높았습니다(7). 기후 과학자, 언론인, 시민 단체는 경험할 수 없는 것을 시각화하기 위해 빙산이 녹고 북극곰이 굶주리는 사진부터 역사적 기온 상승에 대한 과학적 그래프에 이르기까지 시각적 대리물에 의존하고 있습니다. 이러한 시각적 프록시는 지구 온도 상승의 대리인 또는 대표 역할을 합니다. 그러나 모든 대리물이 그렇듯, 동일한 이미지가 믿음과 불신을 동시에 조장할 수 있다는 양면성을 지니고 있습니다.  예를 들어, 내셔널 지오그래픽이 서머셋 섬에서 촬영한 \"얼음이 없는 땅에서 굶주린 북극곰의 가슴 아픈 영상\"(그림 34)은 전 세계 기후 변화의 영향에 대한 분노를 촉발시키며 입소문을 탔습니다(8). 이에 대해 보수적인 뉴스 매체와 폴라베어스 인터내셔널과 같은 의심스러운 야생동물 '보호' 사이트는 경쟁적으로 \"얼음이 없는 땅에서 굶주린 북극곰을 보여주는 가슴 아픈 비디오\"(내셔널 지오그래픽, 2017년 12월 7일)의 34 스틸 프레임을 퍼뜨렸습니다. 영상: 폴 니클렌, https:// www.nationalgeographic.com/science/article/polar-bear-starving-arctic-sea-ice-melt -climate-change-spd. 곰의 상태에 대한 설명과 함께 '비극 포르노(9)'라는 비난을 받은 SeaLegacy. 이미지가 설득력이 있고 인기가 많을수록 더 많은 논란과 분석, 음모론이 만들어지고 유포됩니다.  프록시는 불확실성을 줄이기도 하고 늘리기도 합니다. 알 수 없거나 부재하는 것을 표현함으로써 알 수 없는 것의 유령을 불러일으키기도 합니다. 현재 진행 중인 기후 변화 논쟁에서 만, 브래들리, 휴즈의 '하키 스틱'(그림 35)보다 더 논란의 여지가 많은 이미지는 없을 것입니다. 카리스마 넘치는 거대 동물과 극적인 자연 환경이 관심과 논쟁을 불러일으키지만, 지구 기후 변화를 가장 영향력 있고 논란의 여지가 있는 표현은 선 그래프입니다.  기후학자 마이클 만, 레이몬드 브래들리, 말콤 휴즈는 1400년부터 1995년까지 북반구 평균 기온의 변화를 그래프로 나타낸 것을 1998년 Nature에 처음 발표했고, 이듬해에는 1000년부터 1998년까지를 포함한 업데이트 버전을 지구물리학 연구 편지(10)에 발표했습니다. 1961-1990년 평균 기온(°C)의 편차 Mann et al., 1999, 재구성(연평균, 전반구) Mann et al., 1999, 재구성(연평균, 30°N~70°N 위도대) Jones et al., 1998, 재구성(여름, 아열대 강조) Briffa, 2000, 재구성(나이테 밀도만, 여름, 아열대) 도구 데이터(연평균, 전반구) 1(0). 0(5). 0(0). -0(5). -1(0). 1000 1200 1400 1600 1800 2000 35 \"하키 스틱\", 그림 4(2)에서 재인용. 마이클 E. 만, 하키 스틱과 기후 전쟁: 최전선으로부터의 파견 (뉴욕: Columbia University Press, 2012), 55. 2001 년 기후 변화에 관한 정부 간 패널 (IPCC) 보고서의 \"정책 입안자를위한 요약\"섹션에 연구자들의 1999 년 그래프가 등장했으며 빌 클린턴 대통령과 앨 고어 부통령과 같은 정치인들은이를 사용하여 인간의 화석 연료 연소가 기후에 미치는 영향을 드러 냈습니다. 동시에 이 이미지는 사회 과학자들과 기후 변화를 부정하는 물리학자들로부터 공격을 받았고, 월스트리트 저널, MIT 테크놀로지 리뷰와 같은 언론 매체와 보수 정치인(11)의 공격을 받았습니다. 또한 만은 '나쁜 과학'의 대리인으로서 개인적으로도 공격을 받았는데, 그와 그의 가족은 살해 협박을 받았고, 공화당 의원들의 소환에 불응했으며, '기후 게이트(12)'의 일환으로 그의 이메일이 해킹당하기도 했습니다. 단순한 그래프가 어떻게 이렇게 많은 분노와 논란을 불러일으킬 수 있었을까요?\n",
      "\n",
      "과거에 집착\n",
      "\n",
      " 만, 브래들리, 휴즈의 하키 스틱이 미래에 대한 예측을 하지 않는다는 점(1999년 그래프에 포함된 마지막 해가 1998년)을 고려하면 이 논란은 기괴해 보입니다. 연구자들의 모델은 예측보다는 설명에 가깝다고 볼 수 있습니다. 하키 스틱은 일반적인 순환 모델을 사용하여 미래 기후 추세를 예측하지 않고 통계적 방법과 나이테 및 얼음 코어 측정과 같은 프록시 데이터를 사용하여 과거 기후를 재구성한 고 기후학 전문 연구자입니다. 하지만 만, 브래들리, 휴즈는 1998년 논문에서 다음과 같이 언급했습니다: \"지난 몇 세기 동안의 기후 변화의 공간적, 시간적 패턴을 모두 아는 것은 산업화 이후 기후에 대한 인위적 영향을 평가하는 데 있어 핵심적인 요소입니다(13). 즉, 재현된 과거를 통해 현재 화석 연료 사용의 영향을 파악할 수 있습니다. 연구진의 1999년 그래프는 유럽, 중국, 호주, 북미 일부 지역에서 비정상적으로 높은 기온을 경험했던 이른바 중세 온난화 기간(\"중세 기후 이상\"이라고도 함)인 1000년부터 1400년까지 북반구의 평균 기온을 재구성한 것이어서 논란이 많았습니다. 도널드 트럼프 대통령의 초대 에너지부 장관인 릭 페리와 같은 기후 변화 부정론자들은 이러한 이상 기후를 근거로 기후 변화는 인간이 아닌 해양과 자연 환경에 의해 주로 발생한다고 주장해 왔습니다(14). 그 주장은 다음과 같습니다: 과거에도 지구가 비슷한 온난화 기간을 겪었다면 현재의 온난화에 대해 인간을 비난할 수 없다는 것입니다. 그러나 하키 스틱 그래프에 따르면 20세기 동안의 온난화(스틱의 날 부분)는 이전의 온도 상승을 훨씬 능가하는 것으로 나타났습니다. 현재와 그 당시의 주요 차이점이 인간이 화석 연료를 태운 것임을 감안할 때, 지구 평균 기온의 훨씬 더 큰 상승에 대한 책임은 인간에게 있음이 틀림없습니다. 만, 브래들리, 휴즈에 대한 '과학적' 공격은 프록시와 통계적 방법의 사용에 초점을 맞췄습니다. 만은 이전의 고기후학자들처럼 시간적, 공간적으로 불균일하게 표본이 추출된 나이테 측정, 얼음 코어, 얼음 용융, 지역 기상 기록 등 다양한 유형의 온도 프록시에서 자료를 얻었습니다. 특히, 만이 2012년 저서에서 설명한 것처럼 \"지구의 제한된 지역인 중위도 대륙만을 나타내는\" 나이테 데이터는 압도적으로 풍부합니다. 산호, 얼음 코어, 호수 퇴적물에서 추출한 데이터인 덜 풍부한 온도 프록시는 극지방, 대양, 열대 지방 등 다른 광대한 지역을 나타냅니다. 이러한 모든 온도 프록시를 동등하게 취급한다면, \"엄청난 양의 나이테 데이터가 다른 프록시 기록의 덜 풍부한 정보를 압도할 것입니다. [따라서] 중위도 대륙에 대한 결과에 가중치가 부여될 것입니다.\"15). 이러한 서로 다른 프록시 간의 \"공정한 싸움\"을 만들기 위해 Mann, Bradley, Hughes는 이전에 물리학자 루돌프 프리젠더퍼가 기상학과 해양학에 도입한 방법인 주성분 분석(PCA)과 특이값 분해(SVD)를 사용했습니다(16). 1장에서 언급하고 4장에서 자세히 설명하겠지만, 주성분 분석은 20세기 초 현대 통계학의 '아버지'이자 생체인식학자이자 우생학자인 칼 피어슨(Karl Pearson)이 처음 개발했습니다(17). PCA는 상관관계 행렬의 '고유 벡터'를 결정하여 상관관계가 있을 수 있는 데이터 포인트 집합(중복 요인을 포함할 수 있는 관측치)을 선형적으로 상관관계가 없는 직교 '주성분' 집합으로 분해합니다(그림 36 및 37 참조). 주성분 분석은 데이터를 일련의 벡터로 분류하여 중요한 패턴을 밝혀내는데, 첫 번째 주성분은 대부분의 데이터가 해당 주성분의 축을 따라 있기 때문에 가장 큰 변동을 설명하고, 두 번째 주성분은 그 다음으로 큰 변동을 설명하는 식으로 데이터를 분류합니다. 간단히 말해, 주성분과 고유 벡터 분석은 새로운 축 세트를 중심으로 최신 데이터를 분석하므로 수학적 계산이 훨씬 쉬워집니다. 만, 브래들리, 휴즈는 주성분 분석을 두 가지 방식으로 사용했습니다. (1) 데이터를 공간적으로 '균등화'하고, (2) 더 큰 데이터 세트에서 주요 변동 패턴을 파악하는 데 사용했습니다.  이들이 생성한 각 고유 벡터는 공간적 구성 요소인 '경험적 직교 함수'와 시간에 따른 주성분으로 모두 분해되었습니다(그림 38). 1400 1500 1600 1700 1800 1900 0(00). -0(10). -0(05). 0(05). 0(00). -0(10). -0(05). 0(05). 0(00). -0(10). -0(05). 0(05). 0(00). -0(10). -0(05). 0(05). 0(00). -0(10). -0(05). 0(05). 0(10). 연도 RPC no. 1 RPC 번호 2 RPC 번호 3 RPC no. 4 RPC no. 5 36 주요 주성분, Michael E. Mann, Raymond S. Bradley, Malcolm K. Hughes, \"지난 6세기 동안의 지구 규모의 온도 패턴과 기후 강제력,\" Nature 392, 6678 (1998)에서 재인용: 783, 그림 5a, https:// meteor.geol.iastate.edu/classes/ge515/papers/Mann_et_al_Nature1998.pdf. 37 \"주성분 분석(PCA)\", Alex Barnett. 37 (계속) 37 (계속) 37 (계속) 38 5개의 주요 고유 벡터에 대한 경험적 직교 함수, Mann, Bradley 및 Hughes, \"GlobalScale Temperature Patterns\", 780, 그림 2, https:// meteor.geol.iastate.edu/classes/ge515/papers/Mann_et_al_Nature1998.pdf에서 재인용. 만, 브래들리, 휴즈에 따르면, 지구 평균 기온 변동성의 88%와 반구 평균 기온 변동성의 73%를 설명하는 첫 번째 고유 벡터는 20세기 동안 평균 기온의 상승을 분명히 보여주었습니다. 반면, 두 번째는 동부 열대 태평양에서 라니냐와 같은 완만한 냉각 추세를 보였습니다. 연구진은 20세기 데이터를 사용하여 이러한 변화 패턴을 확인했는데, 당시에는 모든 프록시가 사용 가능했기 때문입니다. 그런 다음 1902~80년 훈련 기간 동안의 연평균 해상도에서 이러한 경험적 고유 벡터에 대해 \"다중 프록시 데이터의 각 지표\"를 특이값 분해(SVD)를 사용하여 보정하여 더 긴 역사적 기간 동안 재구성된 주성분을 생성하는 데 도움을 주었습니다(18). 각 주성분은 측정된 변수 또는 프록시의 일부 또는 전체에 가중치를 부여한 합으로, 예를 들어 첫 번째 주성분은 한 프록시에 0.5, 다른 프록시에 0.25의 가중치를 부여할 수 있습니다. 재구성된 주성분을 검증하기 위해 연구진은 20세기 이전 기간의 실제 데이터(따라서 하키 스틱 위와 아래의 오차 막대)에 대해 구성 요소의 예측을 테스트했습니다. 또한 각 고유 벡터와 기간에 대해 모든 프록시를 사용할 수 있거나 관련성이 있는 것은 아니므로 기간에 따라 사용된 프록시 및 고유 벡터의 수를 변경했습니다. 예를 들어 1820년 이후의 재구성에서는 112개 지표의 전체 멀티프록시 네트워크를 사용하여 11개의 고유 벡터를 해결한 반면, 1820년부터 1760년까지의 기간에는 93개 지표를 사용하여 9개의 고유 벡터를 해결했습니다. 사용 가능한 프록시와 해결된 고유 벡터의 수는 각 기간에 따라 감소했습니다. 연구진이 발견한 가장 중요한 5개의 재구성된 주성분 중 첫 번째는 시간이 지남에 따라 온도가 상승하는 것으로 나타났고, 두 번째는 관련 경험적 직교 함수에 따라 온도가 약간 감소하는 것으로 나타났습니다. 이 분석을 통해 그들은 가장 중요한 패턴이 북반구의 기온 상승이라는 것을 알아냈습니다. 비평가들은 만, 브래들리, 휴즈의 프록시 사용과 훈련 세트에 대해 공격했습니다. 2003년 하버드 스미소니언 천체물리학 센터의 천체물리학자 윌리 순과 샐리 발유나스는 기후 연구 저널에서 멀티프록시 네트워크가 본질적으로 부정확하다고 주장했습니다: \"프록시 지표의 결과는 반구적 또는 전지구적 정량적 종합으로 결합될 수 없으며\" 오히려 \"개별 전문가 의견의 앙상블로 간주되어야 한다\"19 즉, 각 개별 프록시, 예를 들어 각 나무 나이테와 얼음 코어에 동등한 목소리를 부여해야 합니다. 그러나 만, 브래들리, 휴즈의 논문에서 중위도 지역의 나이테 데이터가 압도적으로 많다는 것은 사실상 중세 시대의 지구 온난화를 노래하는 이들 데이터에만 귀를 기울였다는 것을 의미했습니다. 그러나 인호프와 같은 부정론자들이 주요 결론을 지지한 순과 발리우나스 논문은 오류로 가득 차 있으며, 논문이 출판되기까지의 동료 검토 과정에도 심각한 결함이 있는 것으로 드러났습니다. 실제로 기후 과학자이자 기후 연구의 편집장이자 만, 브래들리, 휴즈의 연구에 대한 비판자인 한스 폰 스트로흐는 다른 편집자들과 함께 항의하며 사임했습니다(20). 2005년에 캐나다의 사업가 스티븐 매킨타이어와 사회 과학자 로스 맥키트릭은 만, 브래들리, 휴즈의 1998년 연구를 검토하고 연구자들이 짧은 보정 기간을 사용했기 때문에 모델에 입력된 모든 데이터가 하키 스틱 패턴을 생성할 것이라고 주장했습니다(21).  맥킨타이어와 맥키트릭의 논문에도 심각한 결함이 있었는데, 그 이유는 그들이 더 긴 보정 기간을 기준으로 데이터를 최근화할 때 온난화를 일으키는 주성분을 제거했기 때문에 그 결과가 만, 브래들리, 휴즈의 논문과 너무 달랐기 때문입니다(22). 만, 브래들리, 휴즈의 하키 스틱을 검증한 2006년 국립과학아카데미의 보고서와 기후 변화를 부정했던 UC 버클리의 물리학자 리처드 뮬러의 2011년 보고서는 하키 스틱 연구에 대한 비판을 효과적으로 침묵시켰습니다. 이전에 맥킨타이어와 맥키트릭의 논문을 지구 기후 변화 연구의 잘못된 과학을 드러낸 '폭탄'이라고 언급했던 뮬러는 코흐 형제로부터 하키 스틱을 '재검토'하도록 자금을 지원받았습니다(23). 그러나 뮬러는 2011년 월스트리트 저널에 발표한 보고서에서 \"실제\" 데이터를 사용하여 북반구의 평균 기온을 재구성한 결과, 온난화 효과가 만, 브래들리, 휴즈가 제안했던 것보다 훨씬 더 뚜렷하다는 사실을 발견했다고 밝혔습니다. 뮬러는 직접 사과하지 않고 이 점을 인정하며 월스트리트 저널에 이렇게 썼습니다: \"연구를 시작했을 때 회의론자들이 정당한 문제를 제기했다고 생각했고, 어떤 결과가 나올지 몰랐습니다. 우리의 연구 결과는 이전 그룹에서 발표한 연구 결과와 비슷한 것으로 나타났습니다. 이는 일부 회의론자들을 설득하지 못했음에도 불구하고 그 그룹들이 연구에 매우 신중을 기했다는 것을 의미한다고 생각합니다. 그들은 데이터 선택, 균질화 및 기타 보정에서 편견을 피할 수 있었습니다(24). 뮬러는 만이 받은 살해 위협과 괴롭힘과는 극명한 대조를 이루는 이러한 노력으로 포린 폴리시에서 상을 받았습니다. '나쁜 과학'의 대리인으로 공격받았던 만은 로렌스리버모어 국립연구소의 대기 과학자 벤자민 샌터(Benjamin D. Santer)와 마찬가지로 기후 변화 과학 분야의 다른 사람들에게 모범이 되었습니다. 만은 특정 기후변화 과학자들을 고립시키고 괴롭히는 캠페인을 세렝게티의 포식자들이 나머지 '무리(25)'에서 가장 취약한 먹이 동물을 골라내는 방식에서 따온 '세렝게티 전략'이라고 불렀습니다.\n",
      "\n",
      "대리 정치 수용\n",
      "\n",
      " 만, 브래들리, 휴즈의 하키 스틱과 코신스키와 동료들의 분석 모델(1장에서 설명)은 유사합니다. 두 연구자 그룹 모두 행렬 분해 방법을 사용했고, 과거와 미래를 재구성하려 했으며, 인증 문제를 해결하기 위해 고군분투했습니다. 과거와 미래가 서로 대응하는 선형성이 이 모델의 근간을 이루고 있습니다. 만, 브래들리, 휴즈가 1998년 논문에서 언급한 것처럼, 이 모델은 세 가지 기본 가정을 바탕으로 합니다: (1) \"다중 프록시 훈련자 네트워크의 지표는 하나 이상의 도구적 훈련 패턴과 선형적으로 관련되어 있다\", (2) 공간과 시간에 걸쳐 선형성(한 지역의 일부에서 샘플링하면 더 큰 지역을 대표한다), (3) 지난 세기의 한 부분 내의 기후 변화의 공간 패턴은 지난 세기 전체의 패턴과 유사하다는 것(26). 이러한 선형성에 대한 심오한 가정은 연구자들의 설명을 뒷받침하며, 보다 일반적으로 프록시의 기초를 형성합니다. 프록시는 본질적으로 \"무죄\"인 것은 아니지만 본질적으로 \"유죄\"인 것도 아닙니다. 프록시는 지구 기후 변화를 이해하고 \"수학적 파괴 무기\"를 만드는 데 있어 핵심적인 역할을 합니다. 미지의 것 또는 부재하는 것을 찾는 데 사용되면 불확실성을 줄이는 역할을 하면서도 불확실성을 증가시킵니다. 프록시는 필요하지만 부적절합니다. 실제로 프록시는 더 일반적으로 직접적인 지식의 부적절함을 지적합니다. 과학사학자이자 큐레이터인 크리스토프 로솔이 주장했듯이, 고기후학은 데이터와 모델 사이의 경계에 문제가 있더라도 프록시를 사용하고 협상해야 합니다(27). 프록시는 근본적으로 '양면성'을 지니고 있으며, 현재 우리의 정치는 모든 수준에서 프록시를 활용하고 있습니다(28). 프록시는 자크 데리다가 '파마콘'이라고 불렀던 보충제 또는 중개자를 구현합니다: \"치료제와 독약의 역할을 동시에 하는 필터(29)\"를 구현합니다. 프록시는 새로운 의존성과 관계를 형성함으로써 환대 대신 대가를 지불함으로써 책임 중 하나를 면제합니다. 프록시는 존재하지 않는 것을 포착하거나 '동기화'함으로써 알려진 것을 확장합니다. 프록시는 논쟁을 불러일으키고 그들이 \"밝혀낸\" 관계에 대한 의문을 제기합니다. 실제로 지구 기후 변화 모델과 소셜 네트워킹 분석 사이의 유사점은 도발적인 질문을 제기합니다: 인간은 언제 어떻게 나무처럼 예측 가능한 존재가 될 수 있을까요? 이 둘은 인간이 선형적으로 행동하도록 현실을 형성하는 데 필요한 '훈련'의 전체 메커니즘과 이러한 훈련을 뒷받침하는 방대한 데이터 수집 네트워크를 모두 가리킵니다. 역설적이게도 이러한 선형성은 동일한 것을 '대량으로' 복제하는 것이 아니라 진위를 자동화하려는 노력을 통해 이루어집니다.\n"
     ]
    }
   ],
   "source": [
    "result = translator.translate_text(full_text, target_lang=\"KO\")\n",
    "print(result.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소개: 세상을 파괴하는 방법, 한 번에 하나의 솔루션 인터넷은 이 세상의 거의 모든 나쁜 일의 근원이 되는 악몽 같은 존재가 되었습니다. 인터넷은 국가와 기업이 공동 생산한 전 세계적인 감시 네트워크, 거짓과 음모론을 퍼뜨리고 사회를 양극화하며 폭력을 유발하고 팬데믹을 장기화하며 지구를 파괴하는 수준의 소비를 조장하는 군사적 심리 작전(PSYOP)을 기반으로 하는 소셜 미디어 알고리즘, 기존의 불평등을 악화하고 인류의 미래를 위협하는 인공지능(AI) 프로그램 등을 탄생시켰습니다. 아이러니한 것은 인터넷과 인공지능이 약속했던 것과는 정반대의 결과를 낳고 있다는 점입니다. 20세기 후반의 인터넷인 사이버 공간은 글로벌 민주주의, 평등, 번영의 새로운 시대를 열 것으로 기대되었습니다. 인공지능은 운전기사, 개인 비서, 전문 고문 등 \"1%\"의 특권을 \"90%\"에게까지 확산시킬 유순한 기계 하인을 생산해낼 것이었습니다. 또한 인공지능은 기계가 인종, 성별, 나이, 신체적 약점을 \"볼 수 없기 때문에\" 차별을 없앨 것입니다.1 사이버 공간은 \"마음의 새로운 고향\"2으로서 말 그대로 육체와 정체성이 중요하지 않은 전자적 개척지이기 때문에 개인이 억압과 국가 주권으로부터 자유로워질 것입니다. 1990년대 중반, 앨 고어 부통령과 미국 사법부 구성원들은 인터넷이 모든 사람에게 발언할 수 있는 공간을 제공한다는 점에서 인터넷을 궁극적인 공공 영역이라고 설명했습니다.3 당시 마이크로소프트의 CEO였던 빌 게이츠,\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 원래 텍스트에서 여러 개의 줄바꿈이 있을 때, 한 개만 남기는 처리\n",
    "eng_text = doc[0].get_text()\n",
    "\n",
    "# 정규 표현식을 사용하여 연속된 줄바꿈(\\n)을 하나로 축약\n",
    "eng_text = re.sub(r'\\n+', '\\n', eng_text)\n",
    "\n",
    "# 남은 하나의 \\n도 공백으로 대체\n",
    "eng_text = eng_text.replace('\\n', ' ')\n",
    "\n",
    "# 필요에 따라 번역\n",
    "result = translator.translate_text(eng_text, target_lang=\"KO\")\n",
    "print(result.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is the title.\n"
     ]
    }
   ],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
